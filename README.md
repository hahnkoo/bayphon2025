# Unsupervised phoneme segmentation using a transformer autoencoder

This github page archives the resources necessary to replicate the poster that I presented on 5/10/2025 at BayPhon2025 organized by UCSC.

I compared three different segmentation approaches: (1) a baseline model, (2) the Montreal Forced Aligner (MFA), and (3) an autoencoder. They were evaluated on the standard test set of the TIMIT corpus.

The relevant resources for each approach are in ```./baseline/```, ```./mfa/```, ```./autoencoder/```, respectively. In particular, the ```hyp``` subdirectory (e.g. ```./baseline/hyp/```) contains segmentation results (```BND``` files). Each ```BND``` file lists phoneme boundary locations in seconds, one boundary per line.

The ```./data/``` directory contains relevant resources from the TIMIT test set. ```./data/timit_test_log_librosa_mel80/``` contains log mel spectrogram representation of each TIMIT recording, which (1) and (3) require as input. ```./data/timit_test_phn/``` contains the ```PHN``` that specify reference boundary locations.

To evaluate segmentation results, run ```eval.py``` along with the path to the ```hyp``` directory containing the ```BND``` files as the argument to ```--hyp_dir``` and the path to the directory containing the ```PHN``` files as the argument to ```--phn_dir```. For example,

```
python eval.py --hyp_dir ./baseline/hyp/ --phn_dir ./data/timit_test_phn/
```

This should print out precision, recall, F-score, oversegmentation rate, and R-value. To show top 10 insertion and deletion errors as well, add ```--error_analysis```:

```
python eval.py --hyp_dir ./baseline/hyp/ --phn_dir ./data/timit_test_phn/ --error_analysis
```

I evaluated the approaches using the standard test set of the TIMIT corpus. The baseline model and the autoencoder expects a log mel spectrogram for each recording as input. The spectrograms are in ```./data/timit_test_log_librosa_mel80/```. The segmentation results for each approach are in the ````hyp``` subdirectory of the corresponding directory: e.g. ```./baseline/hyp/``` for the baseline model.

Below I describe how the code for each approach can be used to recreate the segmentation results in the ```hyp``` directory.

### Baseline 

Enter the following in ```./baseline/```:

```
python segment.py --csv_dir ../data/timit_test_log_librosa_mel80/ --outdir hyp/ --normalize
```

### Montreal Forced Aligner (MFA)

The segmentation results can be generated by installing and running MFA on your computer.

Follow the instruction [here](https://montreal-forced-aligner.readthedocs.io/en/latest/installation.html) for installation.

Follow the instruction [here](https://eleanorchodroff.com/tutorial/montreal-forced-aligner.html) by Eleana Chodroff to run MFA. Let me elaborate a bit below.

Running MFA requires you to provide ```lab``` files along with the ```WAV``` files from the TIMIT corpus. The ```lab``` files for the TIMIT test corpus are in the ```timit_test_labs``` subdirectory. To generate them yourself, run ```wrd2lab.py``` to convert the ```WRD``` files in the TIMIT corpus to the corresponding ```lab``` files.

You also need to provide a pretrained acoustic model and a pronunciation lexicon. I downloaded and used the ```english_us_arpa``` versions for this study.

With the ```lab``` files and the corresponding ```WAV``` files placed in ```timit_test_labs```, I ran the following command in the ```mfa``` directory:

```
mfa align -s 14 --clean ./timit_test_labs/ english_us_arpa english_us_arpa ./hyp/
```

```-s 14``` because the first 14 characters of the filename specify the speaker identity: ```TEST_DR8_MSLB0``` in ```TEST_DR8_MSLB0_SX383.lab```.

This will store the segmentation result as TextGrid files in the ```hyp``` directory.

To translate the TextGrid files to ```BND``` files, run ```textgrid2bnd.py```.

### Autoencoder

Enter the following in the ```autoencoder``` directory:

```
python main.py --test_csv_dir ../data/timit_test_log_librosa_mel80/ --test_csv_list timit_test.csvlist --outdir ./hyp/ 
```

To display a figure (like the one in the poster) that illustrates the autoencoder output, run the command with ```--plot``` turned on and ```--plot_phn``` along with the PHN file specifying the reference boundaries. For example,

```
python main.py --test_csv_dir ../data/timit_test_log_librosa_mel80/ --test_csv_list test_dr1_mjsw0_sa2.csvlist --plot --plot_phn ../data/timit_test_phn/TEST_DR1_MJSW0_SA2.PHN 
```

This will generate ```out.png``` which illustrates how the model processed ```TEST_DR1_MJSW0_SA2```.
